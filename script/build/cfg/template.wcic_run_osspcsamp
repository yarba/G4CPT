#!/usr/bin/env bash


#input args
JOBS_ID=${SLURM_ARRAY_TASK_ID}

# PROCID starts at 0
#
# --> LOOP_ID=${SLURM_PROCID}
LOOP_ID=$((1+${SLURM_PROCID}))
NUMA_ID=`expr ${LOOP_ID} - 1`

#set ulimit: number of open files (-n) and stack size [kB] (-s)
ulimit -n 100000
ulimit -s 1000000

#file control index
QLOOP=${JOBS_ID}_${LOOP_ID}

#parameters of template envs
EXE_NAME=G4P_APPLICATION_EXE
CFG_FILE=G4P_APPLICATION_CFG
INPUT_FILE=G4P_INPUT_FILE
OUTPUT_DIR=G4P_OUTPUT_DIR
SPOOL_DIR=G4P_SPOOL_DIR
APPLICATION_DIR=G4P_APPLICATION_DIR

if [ ! -d ${OUTPUT_DIR} ] 
then
  echo "OUTPUT_DIRECTORY ${OUTPUT_DIR} does not exist, aborting."
  exit 2
fi

#Applications will take these environment variables
export PERFORMANCE=G4P_PERFORMANCE_FLAG
export PHYSLIST=G4P_PHYSICS_LIST

#pbs work dir for each job - multiple jobs running on the same worker node
PBS_WORK_DIR=${SPOOL_DIR}_${QLOOP}

[ -d ${PBS_WORK_DIR} ] && rm -r ${PBS_WORK_DIR} 
mkdir -p ${PBS_WORK_DIR}
cd ${PBS_WORK_DIR}

# --> Jan.2021 migration to WC-IC
#
# Setup OSS
#
export HOME=/work1/g4p/${USER}
module load gnu8/8.3.0
module load binutils/2.31.90
export SPACK_ROOT=/work1/g4p/g4p/products/spack
. ${SPACK_ROOT}/share/spack/setup-env.sh
spack load openspeedshop


mkdir ${PBS_WORK_DIR}/raw
mkdir ${PBS_WORK_DIR}/db
export OPENSS_RAWDATA_DIR=${PBS_WORK_DIR}/raw
export OPENSS_DB_DIR=${PBS_WORK_DIR}/db

# setup for application
source ${APPLICATION_DIR}/setenv_pbs.sh

export PATH=${APPLICATION_DIR}/bin:${PATH}

if [ ! -f ${INPUT_FILE} ]
then
  SLT=$((${RANDOM}%60+1))
  echo "Will sleep ${SLT} seconds before copying ${INPUT_FILE}"
  sleep ${SLT}

  e100MeV_flag=`echo ${OUTPUT_DIR} | grep "e\-100MeV"`

  if [ x"${e100MeV_flag}" = x"${OUTPUT_DIR}" ]; then
    cp /work1/g4p/g4p/mcdata/e-100MeV_event.data ${INPUT_FILE}
  else
    cp /work1/g4p/g4p/mcdata/pythia_event.data ${INPUT_FILE}
  fi

  if [ x"${EXE_NAME}" = x"cmsExp" -o x"${EXE_NAME}" = x"cmsExpMT" ]; then
    ln -s ../cmsExp.gdml cmsExp.gdml
  fi
fi

if [ ! -f ${CFG_FILE} ]
then
  cp ${OUTPUT_DIR}/${CFG_FILE} .
fi

NOTE_FILE=${PBS_WORK_DIR}/note_g4profiling_${QLOOP}
echo "Loop begin at: `date`"            > ${NOTE_FILE}
echo "Scratch dir is: ${PBS_WORK_DIR}" >> ${NOTE_FILE}

cat /proc/cpuinfo /proc/meminfo    > run_env_${QLOOP}.txt
echo "nodename: `uname -n`"       >> run_env_${QLOOP}.txt
echo "kernel_version: `uname -r`" >> run_env_${QLOOP}.txt
echo  -n "os:                   " >> run_env_${QLOOP}.txt
cat /etc/redhat-release           >> run_env_${QLOOP}.txt
echo "processor_type: `uname -p`" >> run_env_${QLOOP}.txt
printenv                          >> run_env_${QLOOP}.txt

echo "${EXE_NAME} begin: `date`" > tmp_trialdata.txt
EXE_NAME_FOR_OSS=`which ${EXE_NAME}` 
SAMPLE_FREQUENCY=1000

echo " Starting osspcsamp of ${EXE_NAME_FOR_OSS} at `date` "

if [ x"${EXE_NAME}" = x"SimplifiedCaloMT" -o \
     x"${EXE_NAME}" = x"cmsExpMT" ]; then
  osspcsamp "${EXE_NAME_FOR_OSS} ${CFG_FILE} 1" ${SAMPLE_FREQUENCY}  > tmp.stdout 2> tmp.stderr &
elif [ x"${EXE_NAME}" = x"lArTest" ]; then
  cp ${APPLICATION_DIR}/lArBox.gdml .
  osspcsamp "${EXE_NAME_FOR_OSS} lArBox.gdml ${CFG_FILE}" ${SAMPLE_FREQUENCY} > tmp.stdout 2> tmp.stderr &
else
  osspcsamp "${EXE_NAME_FOR_OSS} ${CFG_FILE}" ${SAMPLE_FREQUENCY} > tmp.stdout 2> tmp.stderr &
fi
PROC_ID=$!

echo "${EXE_NAME} process id is: ${PROC_ID}"       >> ${NOTE_FILE}

ps xjfwww                         >> run_env_${QLOOP}.txt

mv tmp_trialdata.txt trialdata_${QLOOP}.txt
mv tmp.stdout stdout_${QLOOP}.txt
mv tmp.stderr stderr_${QLOOP}.txt

wait ${PROC_ID}
echo "${EXE_NAME} end: `date`"         >> trialdata_${QLOOP}.txt

echo "doing ls -la" >> stdout_${QLOOP}.txt
ls -la        >> stdout_${QLOOP}.txt

echo "doing ls -la" >> run_env_${QLOOP}.txt
ls -la        >> run_env_${QLOOP}.txt

grep 'TimeEvent>'  stdout_${QLOOP}.txt  > eventdata_${QLOOP}.txt
grep 'TimeReport>' stdout_${QLOOP}.txt >> trialdata_${QLOOP}.txt
grep 'MemoryEvt>'  stdout_${QLOOP}.txt  > memorydata_${QLOOP}.txt
if [ x"${PERFORMANCE}" = x"EXTENDED" ]; then
  grep 'NStepping>' stdout_${QLOOP}.txt  > steppingdata_${QLOOP}.txt
fi

echo "after run"                       >> run_env_${QLOOP}.txt
printenv                               >> run_env_${QLOOP}.txt

echo " Starting openss at `date` "

#
# oss pcsamp post analysis: exclusive time
#
echo "expview" > names.oss
echo "exit" >> names.oss
openss -cli -f ${PBS_WORK_DIR}/db/${EXE_NAME}-pcsamp-0.openss < names.oss >& profdata_${QLOOP}_names

# output tar file
TAR_FILE=${PBS_WORK_DIR}/g4profiling_${QLOOP}.tgz
mv ${PBS_WORK_DIR}/db/${EXE_NAME}-pcsamp-0.openss \
   ${PBS_WORK_DIR}/${EXE_NAME}-pcsamp_${QLOOP}.openss

echo "tar file for this loop: ${TAR_FILE}" >> ${NOTE_FILE}
echo "PID for this loop: ${PROC_ID}"       >> ${NOTE_FILE}
echo "Loop end at: `date`"                 >> ${NOTE_FILE}

echo " Starting tar-ing results at `date` "

tar zcf ${TAR_FILE}  *_${QLOOP}.* profdata_${QLOOP}_* ${NOTE_FILE}

echo " Starting rsync transfer of results at `date` "

#copy output tar files from the local disk to the shared disk and clean up
#
rsync ${TAR_FILE} ${OUTPUT_DIR}
rm ${TAR_FILE}

rm ${INPUT_FILE}

#assuming only one core file
for ff in core.*
  do
  fff=${ff#core_${QLOOP}}
  if [ $ff = $fff ]
      then
      if [ -f ${fff} ]
	  then
	  mv ${ff}  core_${QLOOP}
      fi
  fi
done

cd ${OUTPUT_DIR}
rm -rf ${PBS_WORK_DIR}


